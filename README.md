<p align="center">
  <img src="assets/logo.png" width="800"/>
</p>

# U-Trans  
## A Foundation Model for Seismic Waveform Representation

U-Trans is a **foundation model for seismic waveform representation** designed to learn transferable, structured embeddings from raw 3-component seismic waveforms.

This repository provides:

- âœ… U-Trans foundation backbone  
- âœ… Self-supervised foundation training pipeline  
- âœ… Latent feature extraction  
- âœ… Modular downstream task architectures  
- âœ… Unified seismic dataset construction pipeline  

---

# ğŸŒ Overview

U-Trans follows a **foundation model paradigm**:

1. Learn a strong, general seismic representation.
2. Expose reusable latent features.
3. Attach modular downstream models for task-specific learning.

The architecture separates:

```
Foundation representation  â†’  Latent features  â†’  Downstream models
```

---


# ğŸ›  Environment Setup

To ensure full reproducibility, this repository provides a YAML configuration file containing the exact conda environment used for development and training.

The environment file includes:

- Python version  
- TensorFlow and deep learning dependencies  
- Scientific computing libraries  
- Visualization tools  
- Required utility packages  

## ğŸ“¦ Create the Environment

After cloning the repository, create the environment using:

```bash
conda env create -f Foundation.yml
```

Then activate it:

```bash
conda activate Foundation
```

This guarantees compatibility with:

- Foundation training
- Downstream tasks
- Data processing
- Evaluation pipelines

Using the provided YAML file ensures consistent results across different systems and hardware setups.

---

# ğŸ§  Architecture

## ğŸ”¹ U-Trans Foundation Backbone

The foundation model consists of:

- U-Net encoderâ€“decoder architecture  
- Transformer bottleneck representation  
- Multi-scale waveform feature extraction  
- Learned latent token embeddings  

---

### ğŸ“¥ Input

```
(B, 6000, 3)
```

Where:

- `B` = batch size  
- `6000` = waveform length  
- `3` = three-component seismic signal  

---

### ğŸ”¹ Latent Representation

U-Trans produces:

```
(B, 75, 80)
```

- 75 latent tokens  
- 80-dimensional embedding per token  

These tokens encode structured waveform representations using transformer layers.

---

### ğŸ”¹ Decoder Feature Stream

The foundation model can also output:

```
(B, 6000, 1)
```

This stream can be directly concatenated with downstream task models.

---

# ğŸ“‚ Data Preparation

A dedicated `data/` folder is provided to construct a unified seismic dataset for foundation training and downstream experiments.

The combined dataset is built from:

- **STEAD** â€“ https://github.com/smousavi05/STEAD  
- **INSTANCE** â€“ https://github.com/INGV/instance  
- **TXED** â€“ https://github.com/chenyk1990/txed  

## ğŸ”½ Download Instructions

1. Download all three datasets from their official repositories.
2. Create a folder in your project directory called:

```
Data_Seismic
```

3. Place the downloaded datasets inside:

```
Data_Seismic/
    â”œâ”€â”€ STEAD/
    â”œâ”€â”€ INSTANCE/
    â””â”€â”€ TXED/
```

4. Run the notebook inside the `data/` folder to merge them.

This generates a unified HDF5 file:

```
DataCollected
```

All waveforms are standardized to:

```
(6000, 3)
```

The combined dataset is used for:

- Foundation pretraining  
- P-wave picking  
- S-wave picking  
- Magnitude estimation  
- Event location  
- Polarity classification  

---

# ğŸ§ª Foundation Training

The `train/` folder contains the **self-supervised reconstruction training pipeline** used to train U-Trans.

During training, waveforms are intentionally corrupted in:

- Time domain  
- Frequency domain  

The model learns to reconstruct the original waveform, enabling robust and transferable representation learning.

## ğŸ“‚ Train Folder Structure

```
train/
â”œâ”€â”€ U-Trans_Train.ipynb
â”œâ”€â”€ EqT_utils_Recon.py
â”œâ”€â”€ IDS_Collected_Data_train.npy
â”œâ”€â”€ IDS_Collected_Data_valid.npy
â””â”€â”€ IDS_Collected_Data_test.npy
```

### File Descriptions

- `U-Trans_Train.ipynb`  
  Main notebook for training the U-Trans foundation model.

- `EqT_utils_Recon.py`  
  Utilities for:
  - Time-domain corruption  
  - Frequency-domain corruption  
  - Data generators  
  - Training configuration  

- `IDS_Collected_Data_train.npy`  
  Trace IDs used for training.

- `IDS_Collected_Data_valid.npy`  
  Trace IDs used for validation.

- `IDS_Collected_Data_test.npy`  
  Trace IDs reserved for evaluation/testing.

ID files can be downloaded from:  
https://drive.google.com/file/d/1UCx7Qnx-IIjSr4gBy_bipM8mI28hFeCQ/view?usp=drive_link

---

# ğŸ— Repository Structure

```
.
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ logo.png
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Collected_Large_Dataset.ipynb
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ U-Trans_Train.ipynb
â”‚   â”œâ”€â”€ EqT_utils_Recon.py
â”‚   â”œâ”€â”€ IDS_Collected_Data_train.npy
â”‚   â”œâ”€â”€ IDS_Collected_Data_valid.npy
â”‚   â””â”€â”€ IDS_Collected_Data_test.npy
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ foundation_usage.ipynb
â”‚   â””â”€â”€ downstream/
â”‚       â”œâ”€â”€ pwave_eqcct/
â”‚       â”œâ”€â”€ swave_eqcct/
â”‚       â”œâ”€â”€ magnitude_ViT/
â”‚       â”œâ”€â”€ location_ConvMixer/
â”‚       â””â”€â”€ polarity_CCT/
â”‚
â”œâ”€â”€ utrans/
â”‚   â”œâ”€â”€ foundation.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â””â”€â”€ layers.py
â”‚
â”œâ”€â”€ weights/
â”‚   â””â”€â”€ UTrans_Foundation.h5
â”‚
â””â”€â”€ README.md
```

---

# ğŸ”Œ Downstream Architectures

Example downstream models are provided inside:

```
examples/downstream/
```

Available architectures include:

- `pwave_eqcct/` â†’ Transformer-based P-wave picking (EQCCT)  
- `swave_eqcct/` â†’ Transformer-based S-wave picking (EQCCT)  
- `magnitude_ViT/` â†’ Magnitude estimation (ViT)  
- `location_ConvMixer/` â†’ Event location (ConvMixer)  
- `polarity_CCT/` â†’ Polarity classification (CCT)  

Each downstream module attaches to the U-Trans latent or decoder representation.

---

# ğŸš€ Using the Foundation Model

Load pretrained weights and extract features:

```python
import os
import sys
import numpy as np

sys.path.insert(0, os.path.abspath(".."))

from utrans.foundation import get_latent_model, get_decoder_model

UNET_WEIGHTS = "../weights/UTrans_Foundation.h5"

latent_model = get_latent_model(UNET_WEIGHTS)

ready_to_concatenate_model, Featuear_Ready_to_Concatenate = \
    get_decoder_model(UNET_WEIGHTS)
```

### Outputs

- Latent tokens â†’ `(B, 75, 80)`  
- Decoder features â†’ `(B, 6000, 1)`  

---

# ğŸ”¬ Design Philosophy

U-Trans is designed to:

- Learn general waveform representations  
- Enable modular downstream experimentation  
- Separate representation learning from task-specific modeling  
- Support transformer-based extensions  
- Scale to multiple seismic tasks  

---

# ğŸ“Œ Key Characteristics

- U-Net multi-scale encoder  
- Transformer bottleneck modeling  
- Token-based latent embedding  
- Modular downstream integration  

---

# ğŸ“ Citation

If you use this repository, please cite:

**U-Trans: a foundation model for seismic waveform representation and enhanced downstream earthquake tasks**  
DOI: 10.1038/s41598-026-41454-x

---

# ğŸ“§ Contact

For questions or collaboration, please open an issue in this repository.

