{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy import read\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "FF = r'Data_Seismic/DataCollected'\n",
    "fall = h5py.File(FF, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fd367",
   "metadata": {},
   "source": [
    "# STEAD DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc905038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loading IDs\n",
    "t1 = np.load('train_EQ.npy')\n",
    "t2 = np.load('valid_EQ.npy')\n",
    "t3 = np.load('test_EQ.npy')\n",
    "t = np.concatenate([t1,t2,t3])\n",
    "\n",
    "# Loading the file and data.\n",
    "file_name = r'Data_Seismic/STEAD/mergedata/merged.hdf5'\n",
    "fl = h5py.File(file_name, 'r')\n",
    "idall = []\n",
    "\n",
    "for k in range(0,len(t)):\n",
    "    \n",
    "    ID = t[k]\n",
    "    dataset = fl.get('data/'+str(ID))\n",
    "\n",
    "    if ID.split('_')[-1] == 'EV':\n",
    "        data = np.array(dataset)                    \n",
    "        spt = int(dataset.attrs['p_arrival_sample']);\n",
    "        sst = int(dataset.attrs['s_arrival_sample']);\n",
    "        coda_end = int(dataset.attrs['coda_end_sample']);\n",
    "        snr = dataset.attrs['snr_db'];\n",
    "        dep = dataset.attrs['source_depth_km']\n",
    "\n",
    "        mag    =   dataset.attrs['source_magnitude']\n",
    "        magtyp =   dataset.attrs['source_magnitude_type']\n",
    "        evlat  =   dataset.attrs['source_latitude']\n",
    "        evlon  =   dataset.attrs['source_longitude']\n",
    "        stlat  =   dataset.attrs['receiver_latitude']\n",
    "        stlon  =   dataset.attrs['receiver_longitude']\n",
    "        datatyp = 'earthquake'\n",
    "        datalabel = 1\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    elif ID.split('_')[-1] == 'NO':\n",
    "        data = np.array(dataset)\n",
    "        spt = 'None'\n",
    "        sst = 'None'\n",
    "        coda_end = 'None'\n",
    "        snr = 'None'\n",
    "        dep = 'None'\n",
    "        mag    =   'None'\n",
    "        magtyp =   'None'\n",
    "        evlat  =   'None'\n",
    "        evlon  =   'None'\n",
    "        stlat  =   dataset.attrs['receiver_latitude']\n",
    "        stlon  =   dataset.attrs['receiver_longitude']\n",
    "        datatyp = 'noise'\n",
    "        datalabel = 0\n",
    "\n",
    "    polar = 'None'\n",
    "    st = read()\n",
    "    st[0].data = data[:,0]\n",
    "    st[1].data = data[:,1]\n",
    "    st[2].data = data[:,2]\n",
    "    st = st.filter(type='bandpass', freqmin = 1.0, freqmax = 45, corners=2, zerophase=True)\n",
    "    st = st.taper(max_percentage=0.01, type='cosine', max_length=2) \n",
    "    data[:,0] = st[0].data\n",
    "    data[:,1] = st[1].data\n",
    "    data[:,2] = st[2].data\n",
    "\n",
    "    g = fall.create_group(ID)\n",
    "    d = g.create_dataset('data',data=data)\n",
    "    g.attrs['p_arrival_sample'] = spt\n",
    "    g.attrs['s_arrival_sample'] = sst\n",
    "    g.attrs['coda_end_sample'] = coda_end\n",
    "    g.attrs['snr_db'] = snr\n",
    "    g.attrs['depth'] = dep\n",
    "    g.attrs['magnitude'] = mag\n",
    "    g.attrs['magnitude_type'] = magtyp\n",
    "    g.attrs['event_lat'] = evlat\n",
    "    g.attrs['event_long'] = evlon\n",
    "    g.attrs['station_lat'] = stlat\n",
    "    g.attrs['station_long'] = stlon  \n",
    "    g.attrs['data_category'] = datatyp\n",
    "    g.attrs['P_polarity'] = polar\n",
    "    g.attrs['event_label'] = datalabel\n",
    "    g.attrs['AI_Set'] = 'STEAD'\n",
    "    \n",
    "    idall.append(ID)\n",
    "                    \n",
    "    \n",
    "fl.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4f1ab",
   "metadata": {},
   "source": [
    "# Texas DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "f = h5py.File(r'Data_Seismic/TEXD/TXED_20231111-001.h5', 'r')\n",
    "eventid=np.load(r'Data_Seismic/TEXD/ID_20231111.npy')\n",
    "\n",
    "\n",
    "for k in range(0,len(eventid)):\n",
    "    \n",
    "    ID = eventid[k]\n",
    "    dataset = f.get(ID)\n",
    "    data = np.array(dataset['data'])\n",
    "\n",
    "    if dataset.attrs['trace_category'] =='earthquake_local':\n",
    "        \n",
    "        spt = int(dataset.attrs['p_arrival_sample']);\n",
    "        sst = int(dataset.attrs['s_arrival_sample']);\n",
    "        coda_end = int(dataset.attrs['coda_end_sample']);\n",
    "        snr = dataset.attrs['snr_db'];\n",
    "        dep = dataset.attrs['ev_depth']\n",
    "\n",
    "        mag    =   dataset.attrs['magnitude']\n",
    "        magtyp =   'None'\n",
    "        evlat  =   dataset.attrs['ev_latitude']\n",
    "        evlon  =   dataset.attrs['ev_longitude']\n",
    "        stlat  =   dataset.attrs['sta_latitude']\n",
    "        stlon  =   dataset.attrs['sta_longitude']\n",
    "        datatyp = 'earthquake'\n",
    "        polar = dataset.attrs['polarity']\n",
    "        datalabel = 1\n",
    "\n",
    "        \n",
    "    else:\n",
    "        spt = 'None'\n",
    "        sst = 'None'\n",
    "        coda_end = 'None'\n",
    "        snr = 'None'\n",
    "        dep = 'None'\n",
    "        mag    =   'None'\n",
    "        magtyp =   'None'\n",
    "        evlat  =   'None'\n",
    "        evlon  =   'None'\n",
    "        stlat  =   dataset.attrs['sta_latitude']\n",
    "        stlon  =   dataset.attrs['sta_longitude']\n",
    "        datatyp = 'noise'\n",
    "        polar = 'None'\n",
    "        datalabel = 0\n",
    "    \n",
    "    g = fall.create_group(ID)\n",
    "    d = g.create_dataset('data',data=data)\n",
    "    g.attrs['p_arrival_sample'] = spt\n",
    "    g.attrs['s_arrival_sample'] = sst\n",
    "    g.attrs['coda_end_sample'] = coda_end\n",
    "    g.attrs['snr_db'] = snr\n",
    "    g.attrs['depth'] = dep\n",
    "    g.attrs['magnitude'] = mag\n",
    "    g.attrs['magnitude_type'] = magtyp\n",
    "    g.attrs['event_lat'] = evlat\n",
    "    g.attrs['event_long'] = evlon\n",
    "    g.attrs['station_lat'] = stlat\n",
    "    g.attrs['station_long'] = stlon  \n",
    "    g.attrs['data_category'] = datatyp\n",
    "    g.attrs['P_polarity'] = polar\n",
    "    g.attrs['event_label'] = datalabel\n",
    "    g.attrs['AI_Set'] = 'Texas'\n",
    "    idall.append(ID)\n",
    "                    \n",
    "    \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ab7d4",
   "metadata": {},
   "source": [
    "# Instance Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# file NAMES\n",
    "# MetaData\n",
    "events_metaname_bz2=r'Data_Seismic/Instance/metadata_Instance_events_v2.csv.bz2' # Either Counts and GroundMotion\n",
    "#noise_metaname=os.path.join(METADIR,'metadata_Instance_noise.csv')\n",
    "# HDF5\n",
    "events_hdfname=r'Data_Seismic/Instance/Instance_events_counts.hdf5'\n",
    "\n",
    "events_metaData = pd.read_csv(events_metaname_bz2, keep_default_na=False, dtype={'station_location_code': object, \n",
    "            'source_mt_eval_mode':object,'source_mt_status': object,'source_mechanism_strike_dip_rake': object, \n",
    "            'source_mechanism_moment_tensor': object, 'trace_p_arrival_time': object, 'trace_s_arrival_time': object})\n",
    "list_eve=['trace_E_min_counts','trace_N_min_counts','trace_Z_min_counts',\n",
    "         'trace_E_max_counts','trace_N_max_counts','trace_Z_max_counts',\n",
    "         'trace_E_median_counts','trace_N_median_counts','trace_Z_median_counts',\n",
    "         'trace_E_mean_counts','trace_N_mean_counts','trace_Z_mean_counts',\n",
    "         'trace_E_pga_perc','trace_N_pga_perc','trace_Z_pga_perc',\n",
    "         'trace_E_pga_cmps2','trace_N_pga_cmps2','trace_Z_pga_cmps2',\n",
    "         'trace_E_pgv_cmps','trace_N_pgv_cmps','trace_Z_pgv_cmps',\n",
    "         'trace_E_snr_db','trace_N_snr_db','trace_Z_snr_db',\n",
    "         'trace_E_sa03_cmps2','trace_N_sa03_cmps2','trace_Z_sa03_cmps2',\n",
    "         'trace_pgv_cmps', 'trace_pga_perc','trace_P_arrival_sample','trace_S_arrival_sample',\n",
    "         'trace_EQT_number_detections','trace_EQT_P_number','trace_EQT_S_number','trace_GPD_P_number','trace_GPD_S_number']\n",
    "\n",
    "\n",
    "for ele in list_eve:\n",
    "    events_metaData[ele] =  pd.to_numeric(events_metaData[ele], errors='coerce')\n",
    "    \n",
    "\n",
    "chosen_lines = []\n",
    "plots_line = 3\n",
    "\n",
    "df_tmp = events_metaData.loc[(events_metaData.trace_P_arrival_sample > 0) & (events_metaData.trace_S_arrival_sample > 0) ]\n",
    "\n",
    "#df_tmp = events_metaData.loc[(events_metaData.trace_P_arrival_sample > 0)]\n",
    "#\n",
    "ntot = df_tmp.shape[0]\n",
    "#print (\"N records: \", ntot, \"% total: \", float(ntot/TOTAL * 100.))\n",
    "#\n",
    "if ntot > 0:\n",
    "    lista = list(df_tmp.sample(n=plots_line, random_state=1).index)\n",
    "    chosen_lines = chosen_lines + lista\n",
    "    chosen_lines\n",
    "else:\n",
    "    print('no waveform found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f563f3dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Def_plot_waveform import split, build_stream, multiple_streams\n",
    "\n",
    "events_h5File = h5py.File(events_hdfname, 'r') # Events in counts\n",
    "filt = False\n",
    "#filt = True\n",
    "freq_min=1\n",
    "freq_max=45\n",
    "h5 = events_h5File\n",
    "wftype='ev_c'\n",
    "\n",
    "for line in range(0,len(df_tmp)):\n",
    "#for line in range(0,10):\n",
    "    \n",
    "    \n",
    "    st, row = build_stream(df_tmp,h5,line,wftype,filt,freq_min,freq_max)\n",
    "    st = st.filter(type='bandpass', freqmin = 1.0, freqmax = 45, corners=2, zerophase=True)\n",
    "    st = st.taper(max_percentage=0.01, type='cosine', max_length=2) \n",
    "\n",
    "    ID = row.trace_name\n",
    "    evlat = row.source_latitude_deg\n",
    "    evlon = row.source_longitude_deg\n",
    "    dep = row.source_depth_km\n",
    "\n",
    "    mag = row.source_magnitude\n",
    "    magtyp = row.source_magnitude_type\n",
    "\n",
    "    stlat = row.station_latitude_deg\n",
    "    stlon = row.station_longitude_deg\n",
    "\n",
    "    datatyp = row.source_type\n",
    "    \n",
    "    spt = row.trace_P_arrival_sample\n",
    "    sst = row.trace_S_arrival_sample\n",
    "\n",
    "    polar = row.trace_polarity\n",
    "    \n",
    "    snr = [row.trace_E_snr_db,row.trace_N_snr_db,row.trace_Z_snr_db]\n",
    "    \n",
    "    coda_end = spt+2*(sst-spt)\n",
    "    if coda_end>6000:\n",
    "        coda_end = 6000\n",
    "    \n",
    "    datalabel = 1\n",
    "    \n",
    "    data = np.zeros((6000,3))\n",
    "    data[:,0] = st[0].data[0:6000]\n",
    "    data[:,1] = st[1].data[0:6000]\n",
    "    data[:,2] = st[2].data[0:6000]\n",
    "    \n",
    "    if (spt<6000) and (sst<6000):\n",
    "        g = fall.create_group(ID)\n",
    "        d = g.create_dataset('data',data=data)\n",
    "        g.attrs['p_arrival_sample'] = spt\n",
    "        g.attrs['s_arrival_sample'] = sst\n",
    "        g.attrs['coda_end_sample'] = coda_end\n",
    "        g.attrs['snr_db'] = snr\n",
    "        g.attrs['depth'] = dep\n",
    "        g.attrs['magnitude'] = mag\n",
    "        g.attrs['magnitude_type'] = magtyp\n",
    "        g.attrs['event_lat'] = evlat\n",
    "        g.attrs['event_long'] = evlon\n",
    "        g.attrs['station_lat'] = stlat\n",
    "        g.attrs['station_long'] = stlon  \n",
    "        g.attrs['data_category'] = datatyp\n",
    "        g.attrs['P_polarity'] = polar\n",
    "        g.attrs['event_label'] = datalabel\n",
    "        g.attrs['AI_Set'] = 'Instance'\n",
    "        idall.append(ID)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f709abcd",
   "metadata": {},
   "source": [
    "# Instance Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76a39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "noise_metaname = r'Data_Seismic/Instance/metadata_Instance_noise.csv.bz2'\n",
    "noise_hdfname =  r'Data_Seismic/Instance/Instance_noise.hdf5'\n",
    "noise_metaData = pd.read_csv(noise_metaname,dtype={'station_location_code': object}, low_memory=False)\n",
    "noise_h5File = h5py.File(noise_hdfname, 'r')   # Noise in counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de5940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Def_plot_waveform import split, build_stream, multiple_streams\n",
    "filt = False\n",
    "#filt = True\n",
    "freq_min=1\n",
    "freq_max=45\n",
    "wftype='noise'\n",
    "#for line in range(0,len(df_tmp)):\n",
    "for line in range(0,len(noise_metaData)):\n",
    "    \n",
    "    \n",
    "    st, row = build_stream(noise_metaData,noise_h5File,line,wftype,filt,freq_min,freq_max)\n",
    "    st = st.filter(type='bandpass', freqmin = 1.0, freqmax = 45, corners=2, zerophase=True)\n",
    "    st = st.taper(max_percentage=0.01, type='cosine', max_length=2) \n",
    "\n",
    "    ID = row.trace_name\n",
    "\n",
    "    stlat = row.station_latitude_deg\n",
    "    stlon = row.station_longitude_deg\n",
    "\n",
    "    datatyp = 'noise'\n",
    "    \n",
    "    spt = 'None'\n",
    "    sst = 'None'\n",
    "    coda_end = 'None'\n",
    "    snr = 'None'\n",
    "    dep = 'None'\n",
    "    mag    =   'None'\n",
    "    magtyp =   'None'\n",
    "    evlat  =   'None'\n",
    "    evlon  =   'None'\n",
    "    datatyp = 'noise'\n",
    "    polar = 'None'\n",
    "    datalabel = 0\n",
    "    \n",
    "    data = np.zeros((6000,3))\n",
    "    data[:,0] = st[0].data[0:6000]\n",
    "    data[:,1] = st[1].data[0:6000]\n",
    "    data[:,2] = st[2].data[0:6000]\n",
    "    \n",
    "    g = fall.create_group(ID)\n",
    "    d = g.create_dataset('data',data=data)\n",
    "    g.attrs['p_arrival_sample'] = spt\n",
    "    g.attrs['s_arrival_sample'] = sst\n",
    "    g.attrs['coda_end_sample'] = coda_end\n",
    "    g.attrs['snr_db'] = snr\n",
    "    g.attrs['depth'] = dep\n",
    "    g.attrs['magnitude'] = mag\n",
    "    g.attrs['magnitude_type'] = magtyp\n",
    "    g.attrs['event_lat'] = evlat\n",
    "    g.attrs['event_long'] = evlon\n",
    "    g.attrs['station_lat'] = stlat\n",
    "    g.attrs['station_long'] = stlon  \n",
    "    g.attrs['data_category'] = datatyp\n",
    "    g.attrs['P_polarity'] = polar\n",
    "    g.attrs['event_label'] = datalabel\n",
    "    g.attrs['AI_Set'] = 'Instance'\n",
    "    \n",
    "    idall.append(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5fb163",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save IDs\n",
    "np.save('IDS_Collected_Data',idall)\n",
    "len(idall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46e65f",
   "metadata": {},
   "source": [
    "# Read Collected File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the file and data.\n",
    "file_name = r'Data_Seismic/STEAD/mergedata/merged.hdf5'\n",
    "FF = r'Data_Seismic/DataCollected'\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "eventid = np.load('IDS_Collected_Data.npy')\n",
    "\n",
    "kl = 5\n",
    "idx = eventid[kl]\n",
    "f = h5py.File(FF, 'r')\n",
    "dataset = f.get(idx)\n",
    "dat = np.array(dataset['data'])\n",
    "if dataset.attrs['data_category']!='noise':\n",
    "    spt = int(dataset.attrs['p_arrival_sample']);\n",
    "    sst = int(dataset.attrs['s_arrival_sample']);\n",
    "    coda_end = int(dataset.attrs['coda_end_sample']);\n",
    "    snr = dataset.attrs['snr_db'];\n",
    "    evlab = dataset.attrs['event_label']\n",
    "    trace_category = dataset.attrs['data_category'];\n",
    "    dic = {\"P_arrival_Sample\":spt,\n",
    "          \"S_arrival_Sample\":sst,\n",
    "          \"Coda_end_sample\":coda_end,\n",
    "          \"SNR(dB)\":snr,\n",
    "          \"Trace Category\":trace_category}        \n",
    "    print(dic)\n",
    "else:\n",
    "    print('Noise')\n",
    "\n",
    "dataset.attrs['AI_Set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4f5a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "font = {\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.rc('font', **font)\n",
    "ax1 = plt.subplot(111)\n",
    "plt.plot(dat[:,2],'k', label = 'Z' , linewidth = 1, markersize=1)\n",
    "ymin,yma = ax1.get_ylim()\n",
    "if dataset.attrs['data_category']!='noise':\n",
    "    plt.vlines(spt,ymin,yma,color='r',linewidth=2, label='P-Sample')\n",
    "    plt.vlines(sst,ymin,yma,color='b',linewidth=2, label='S-Sample')\n",
    "    plt.legend(loc='lower right', fontsize = 14)\n",
    "plt.xlim([0,6000])\n",
    "plt.xlabel('Samples',font='bold')\n",
    "fig.savefig('Example_Data2.png', bbox_inches='tight',transparent=True, dpi =100)\n",
    "    \n",
    "f.close()\n",
    "\n",
    "spt,sst,coda_end,snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3710d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
