{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3d70e2",
   "metadata": {},
   "source": [
    "# U-Trans + ViT  \n",
    "## California STEAD Example (Event magnitude)\n",
    "\n",
    "This example demonstrates training and testing an **earthquake magnitude model** using:\n",
    "\n",
    "- **U-Trans foundation backbone**\n",
    "- **ViT regression model**\n",
    "- **California subset of the STEAD dataset**\n",
    "\n",
    "---\n",
    "\n",
    "#  Dataset\n",
    "\n",
    "## STEAD (Stanford Earthquake Dataset)\n",
    "\n",
    "**STEAD** (Stanford Earthquake Dataset) is a large-scale seismic waveform dataset containing:\n",
    "\n",
    "- 3-component waveform recordings  \n",
    "- Event metadata (including magnitude)\n",
    "\n",
    "In this example:\n",
    "\n",
    "- Only the **California region subset** is used.\n",
    "- Waveform length is fixed to **6000 samples**.\n",
    "- Input shape is **(6000, 3)** representing three-component seismic data.\n",
    "- Ground-truth event magnitude is used as regression targets.\n",
    "\n",
    "---\n",
    "\n",
    "#  Purpose of This Example\n",
    "\n",
    "This pipeline demonstrates how to:\n",
    "\n",
    "- Train a magnitude regression model on California STEAD traces  \n",
    "- Predict earthquake magnitude  \n",
    "- Evaluate spatial prediction performance  \n",
    "- Test the trained model on a held-out test set  \n",
    "\n",
    "This setup reproduces the California STEAD experiment using the **U-Trans + ViT architecture** for event localization.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa680af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.compat.v1 as tf1\n",
    "tf1.disable_v2_behavior()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[2], True)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.config.experimental.set_visible_devices(physical_devices[0], 'GPU')\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315744a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import logging\n",
    "import warnings\n",
    "import contextlib\n",
    "import multiprocessing\n",
    "import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import signal\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, Flatten, Reshape, Activation,\n",
    "    Conv1D, MaxPooling1D, UpSampling1D, BatchNormalization,\n",
    "    Add, concatenate, DepthwiseConv1D\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "import faulthandler\n",
    "faulthandler.enable()\n",
    "\n",
    "# External utilities (as in your original code)\n",
    "from EqT_utils_Mag import DataGenerator, _lr_schedule\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad820b9e",
   "metadata": {},
   "source": [
    "## Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_depth_rate = 0.1\n",
    "positional_emb = False\n",
    "conv_layers = 1\n",
    "num_classes = 1\n",
    "projection_dim = 80\n",
    "num_heads = 4\n",
    "transformer_units = [projection_dim, projection_dim]\n",
    "transformer_layers = 4\n",
    "\n",
    "\n",
    "def convF1(inpt, D1, fil_ord, Dr):\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    #filters = inpt._keras_shape[channel_axis]\n",
    "    filters = int(inpt.shape[-1])\n",
    "    \n",
    "    #infx = Activation(tf.nn.gelu')(inpt)\n",
    "    pre = Conv1D(filters,  fil_ord, strides =(1), padding='same',kernel_initializer='he_normal')(inpt)\n",
    "    pre = BatchNormalization()(pre)    \n",
    "    pre = Activation('linear')(pre)\n",
    "    \n",
    "    #shared_conv = Conv1D(D1,  fil_ord, strides =(1), padding='same')\n",
    "    \n",
    "    inf  = Conv1D(filters,  fil_ord, strides =(1), padding='same',kernel_initializer='he_normal')(pre)\n",
    "    inf = BatchNormalization()(inf)    \n",
    "    inf = Activation('linear')(inf)\n",
    "    inf = Add()([inf,inpt])\n",
    "    \n",
    "    inf1  = Conv1D(D1,  fil_ord, strides =(1), padding='same',kernel_initializer='he_normal')(inf)\n",
    "    inf1 = BatchNormalization()(inf1)  \n",
    "    inf1 = Activation('linear')(inf1)    \n",
    "    encode = Dropout(Dr)(inf1, training=False)\n",
    "\n",
    "    return encode\n",
    "\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class StochasticDepth(layers.Layer):\n",
    "    def __init__(self, drop_prop, **kwargs):\n",
    "        super(StochasticDepth, self).__init__(**kwargs)\n",
    "        self.drop_prob = drop_prop\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_prob\n",
    "            shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n",
    "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            return (x / keep_prob) * random_tensor\n",
    "        return x\n",
    "\n",
    "\n",
    "class CCTTokenizer1(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        pooling_kernel_size=3,\n",
    "        pooling_stride=(1,1,1,1),\n",
    "        num_conv_layers=conv_layers,\n",
    "        num_output_channels=[int(projection_dim)] * 8,\n",
    "        positional_emb=positional_emb,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CCTTokenizer1, self).__init__(**kwargs)\n",
    "\n",
    "        self.conv_model = tf.keras.Sequential()\n",
    "        for i in range(num_conv_layers):\n",
    "            self.conv_model.add(\n",
    "                layers.Conv1D(\n",
    "                    num_output_channels[i],\n",
    "                    kernel_size,\n",
    "                    stride,\n",
    "                    padding=\"same\",\n",
    "                    use_bias=False,\n",
    "                    activation=\"relu\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.positional_emb = positional_emb\n",
    "\n",
    "    def call(self, images):\n",
    "        outputs = self.conv_model(images)\n",
    "        reshaped = tf.reshape(outputs, (-1, tf.shape(outputs)[1], tf.shape(outputs)[2]))\n",
    "        return outputs\n",
    "\n",
    "    def positional_embedding(self, image_size):\n",
    "        if self.positional_emb:\n",
    "            dummy_inputs = tf.ones((1, image_size, 1))\n",
    "            dummy_outputs = self.call(dummy_inputs)\n",
    "            sequence_length = int(dummy_outputs.shape[1])\n",
    "            projection_dim = int(dummy_outputs.shape[-1])\n",
    "\n",
    "            embed_layer = layers.Embedding(input_dim=sequence_length, output_dim=projection_dim)\n",
    "            return embed_layer, sequence_length\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def create_cct_model1(inputs):\n",
    "    cct_tokenizer = CCTTokenizer1()\n",
    "    encoded_patches = cct_tokenizer(inputs)\n",
    "\n",
    "    if positional_emb:\n",
    "        pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n",
    "        positions = tf.range(start=0, limit=seq_length, delta=1)\n",
    "        position_embeddings = pos_embed(positions)\n",
    "        encoded_patches += position_embeddings\n",
    "\n",
    "    dpr = [x for x in np.linspace(0, stochastic_depth_rate, transformer_layers)]\n",
    "\n",
    "    for i in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        attention_output = StochasticDepth(dpr[i])(attention_output)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-5)(x2)\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "\n",
    "        x3 = StochasticDepth(dpr[i])(x3)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    representation = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "    return representation\n",
    "\n",
    "\n",
    "def UNET(inputs, D1):\n",
    "    D2 = int(D1 * 2)\n",
    "    D3 = int(D2 * 2)\n",
    "    D4 = int(D3 * 2)\n",
    "    D5 = int(D4 * 2)\n",
    "\n",
    "    conv1 = Conv1D(D1, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv1D(D1, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=(2))(conv1)\n",
    "\n",
    "    conv2 = Conv1D(D2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv1D(D2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=(2))(conv2)\n",
    "\n",
    "    conv3 = Conv1D(D3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv1D(D3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=(2))(conv3)\n",
    "\n",
    "    conv4 = Conv1D(D4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv1D(D4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    pool4 = MaxPooling1D(pool_size=(2))(conv4)\n",
    "\n",
    "    conv44 = Conv1D(D5, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv44 = Conv1D(D5, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv44)\n",
    "    pool44 = MaxPooling1D(pool_size=(5))(conv44)\n",
    "\n",
    "    conv5 = Conv1D(D5, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool44)\n",
    "    conv5 = Conv1D(D5, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "\n",
    "    drop5 = create_cct_model1(conv5)\n",
    "\n",
    "    up66 = Conv1D(D5, 3, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling1D(size=(5))(drop5))\n",
    "    merge66 = concatenate([pool4, up66], axis=-1)\n",
    "    conv66 = Conv1D(D5, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge66)\n",
    "    conv66 = Conv1D(D5, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv66)\n",
    "\n",
    "    up6 = Conv1D(D4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling1D(size=(2))(conv66))\n",
    "    merge6 = concatenate([conv4, up6], axis=-1)\n",
    "    conv6 = Conv1D(D4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv1D(D4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv1D(D3, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling1D(size=(2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=-1)\n",
    "    conv7 = Conv1D(D3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv1D(D3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv1D(D2, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling1D(size=(2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=-1)\n",
    "    conv8 = Conv1D(D2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv1D(D2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv1D(D1, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling1D(size=(2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=-1)\n",
    "    conv9 = Conv1D(D1, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv1D(D1, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "\n",
    "    return conv9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38052029",
   "metadata": {},
   "source": [
    "## ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_sampling = 50\n",
    "drop_rate = 0.2\n",
    "input_shape = (6000,3)\n",
    "\n",
    "\n",
    "num_classes = 1\n",
    "input_shapeX = (75, 32)\n",
    "image_sizeX = 75  # We'll resize input images to this size\n",
    "patch_sizeX = 5  # Size of the patches to be extract from the input images\n",
    "num_patchesX = (image_sizeX // patch_sizeX)\n",
    "projection_dimX = 100\n",
    "num_headsX = 4\n",
    "transformer_unitsX = [\n",
    "    projection_dimX * 2,\n",
    "    projection_dimX,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layersX = 4\n",
    "\n",
    "def mlpX(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        #x = layers.Dense(units, activation='relu')(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class PatchesX(layers.Layer):\n",
    "    def __init__(self, patch_sizeX, **kwargs):\n",
    "        super(PatchesX, self).__init__()\n",
    "        self.patch_sizeX = patch_sizeX\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'patch_sizeX' : self.patch_sizeX, \n",
    "            \n",
    "        })\n",
    "        \n",
    "        return config\n",
    "        \n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_sizeX, 1, 1],\n",
    "            strides=[1, self.patch_sizeX, 1, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "    \n",
    "\n",
    "class PatchEncoderX(layers.Layer):\n",
    "    def __init__(self, num_patchesX, projection_dimX, **kwargs):\n",
    "        super(PatchEncoderX, self).__init__()\n",
    "        self.num_patchesX = num_patchesX\n",
    "        self.projection = layers.Dense(units=projection_dimX)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patchesX, output_dim=projection_dimX\n",
    "        )\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'num_patchesX' : self.num_patchesX, \n",
    "            'projection_dimX' : projection_dimX, \n",
    "            \n",
    "        })\n",
    "        \n",
    "        return config\n",
    "    \n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patchesX, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        \n",
    "        return encoded\n",
    "    \n",
    "def create_vit_classifier(inputs,inp):\n",
    "    \n",
    "    filters = [32, 64, 96, 128, 256] \n",
    "\n",
    "    x = convF1(inputs,   80, 13, 0.1)\n",
    "    x = convF1(x,   80, 13, 0.1)\n",
    "    x = convF1(x,   80, 13, 0.1)\n",
    "    x = Flatten()(x)\n",
    "    x =  Reshape((6000,1))(x)\n",
    "    x = concatenate([x,inp])\n",
    "    \n",
    "     \n",
    "    e = Conv1D(filters[1], 3, padding = 'same')(x) \n",
    "    e = Dropout(drop_rate)(e, training=False)\n",
    "    e = MaxPooling1D(2, padding='same')(e)\n",
    "\n",
    "    \n",
    "    e = Conv1D(filters[1], 3, padding = 'same')(e) \n",
    "    e = Dropout(drop_rate)(e, training=False)\n",
    "    e = MaxPooling1D(2, padding='same')(e)\n",
    "    \n",
    "    \n",
    "    e = Conv1D(filters[0], 3, padding = 'same')(e) \n",
    "    e = Dropout(drop_rate)(e, training=False)\n",
    "    e = MaxPooling1D(2, padding='same')(e)\n",
    "    \n",
    "    e = Conv1D(filters[0], 3, padding = 'same')(e) \n",
    "    e = Dropout(drop_rate)(e, training=False)\n",
    "    e = MaxPooling1D(2, padding='same')(e)\n",
    "    \n",
    "        \n",
    "    e = Conv1D(filters[0], 3, padding = 'same')(e) \n",
    "    e = Dropout(drop_rate)(e, training=False)\n",
    "    e = MaxPooling1D(5, padding='same')(e)\n",
    "    \n",
    "    \n",
    "    #print(e)\n",
    "    inputreshaped = layers.Reshape((75,1,32))(e)\n",
    "    # Create patches.\n",
    "    patches = PatchesX(patch_sizeX)(inputreshaped)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoderX(num_patchesX, projection_dimX)(patches)\n",
    "    \n",
    "    \n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layersX):\n",
    "        #encoded_patches = convF1(encoded_PatchesX, projection_dimX,11, 0.1)\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_headsX, key_dim=projection_dimX, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # mlpX.\n",
    "        x3 = mlpX(x3, hidden_units=transformer_unitsX, dropout_rate=0.1)\n",
    "        #x3 = convF1(x3, projection_dimX,11, 0.1)\n",
    "\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dimX] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "\n",
    "    # Add mlpX.\n",
    "    features = mlpX(representation, hidden_units=[1000,500], dropout_rate=0.5)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ebbbf",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainer1(input_hdf5=None,\n",
    "            output_name=None,                \n",
    "            input_dimention=(6000, 3),\n",
    "            shuffle=True, \n",
    "            label_type='gaussian',\n",
    "            normalization_mode='std',\n",
    "            augmentation=True,\n",
    "            add_event_r=0.6,\n",
    "            shift_event_r=0.99,\n",
    "            add_noise_r=0.3, \n",
    "            drop_channel_r=0.5,\n",
    "            add_gap_r=0.2,\n",
    "            scale_amplitude_r=None,\n",
    "            pre_emphasis=False,                \n",
    "            mode='generator',\n",
    "            batch_size=200,\n",
    "            epochs=200, \n",
    "            monitor='val_loss',\n",
    "            patience=12,\n",
    "            multi_gpu=False,\n",
    "            number_of_gpus=4,\n",
    "            gpuid=None,\n",
    "            gpu_limit=None,\n",
    "            use_multiprocessing=True):\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    Generate a model and train it.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_hdf5: str, default=None\n",
    "        Path to an hdf5 file containing only one class of data with NumPy arrays containing 3 component waveforms each 1 min long.\n",
    "\n",
    "\n",
    "    output_name: str, default=None\n",
    "        Output directory.\n",
    "        \n",
    "    input_dimention: tuple, default=(6000, 3)\n",
    "        OLoss types for S picking respectively. \n",
    "\n",
    "    shuffle: bool, default=True\n",
    "        To shuffle the list prior to the training.\n",
    "\n",
    "    label_type: str, default='triangle'\n",
    "        Labeling type. 'gaussian', 'triangle', or 'box'. \n",
    "\n",
    "    normalization_mode: str, default='std'\n",
    "        Mode of normalization for data preprocessing, 'max': maximum amplitude among three components, 'std', standard deviation. \n",
    "\n",
    "    augmentation: bool, default=True\n",
    "        If True, data will be augmented simultaneously during the training.\n",
    "\n",
    "    add_event_r: float, default=0.6\n",
    "        Rate of augmentation for adding a secondary event randomly into the empty part of a trace.\n",
    "\n",
    "    shift_event_r: float, default=0.99\n",
    "        Rate of augmentation for randomly shifting the event within a trace.\n",
    "      \n",
    "    add_noise_r: float, defaults=0.3 \n",
    "        Rate of augmentation for adding Gaussian noise with different SNR into a trace.       \n",
    "        \n",
    "    drop_channel_r: float, defaults=0.4 \n",
    "        Rate of augmentation for randomly dropping one of the channels.\n",
    "\n",
    "    add_gap_r: float, defaults=0.2 \n",
    "        Add an interval with zeros into the waveform representing filled gaps.       \n",
    "        \n",
    "    scale_amplitude_r: float, defaults=None\n",
    "        Rate of augmentation for randomly scaling the trace. \n",
    "              \n",
    "    pre_emphasis: bool, defaults=False\n",
    "        If True, waveforms will be pre-emphasized. Defaults to False.  \n",
    "        \n",
    "          \n",
    "    mode: str, defaults='generator'\n",
    "        Mode of running. 'generator', or 'preload'. \n",
    "         \n",
    "    batch_size: int, default=200\n",
    "        Batch size.\n",
    "          \n",
    "    epochs: int, default=200\n",
    "        The number of epochs.\n",
    "          \n",
    "    monitor: int, default='val_loss'\n",
    "        The measure used for monitoring.\n",
    "           \n",
    "    patience: int, default=12\n",
    "        The number of epochs without any improvement in the monitoring measure to automatically stop the training.          \n",
    "        \n",
    "    multi_gpu: bool, default=False\n",
    "        If True, multiple GPUs will be used for the training. \n",
    "           \n",
    "    number_of_gpus: int, default=4\n",
    "        Number of GPUs uses for multi-GPU training.\n",
    "           \n",
    "    gpuid: int, default=None\n",
    "        Id of GPU used for the prediction. If using CPU set to None. \n",
    "         \n",
    "    gpu_limit: float, default=None\n",
    "        Set the maximum percentage of memory usage for the GPU.\n",
    "        \n",
    "    use_multiprocessing: bool, default=True\n",
    "        If True, multiple CPUs will be used for the preprocessing of data even when GPU is used for the prediction. \n",
    "\n",
    "        \n",
    "    \"\"\"     \n",
    "\n",
    "\n",
    "    args = {\n",
    "    \"input_hdf5\": input_hdf5,\n",
    "    \"output_name\": output_name,\n",
    "    \"input_dimention\": input_dimention,\n",
    "    \"shuffle\": shuffle,\n",
    "    \"label_type\": label_type,\n",
    "    \"normalization_mode\": normalization_mode,\n",
    "    \"augmentation\": augmentation,\n",
    "    \"add_event_r\": add_event_r,\n",
    "    \"shift_event_r\": shift_event_r,\n",
    "    \"add_noise_r\": add_noise_r,\n",
    "    \"add_gap_r\": add_gap_r,\n",
    "    \"drop_channel_r\": drop_channel_r,\n",
    "    \"scale_amplitude_r\": scale_amplitude_r,\n",
    "    \"pre_emphasis\": pre_emphasis,\n",
    "    \"mode\": mode,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,\n",
    "    \"monitor\": monitor,\n",
    "    \"patience\": patience,           \n",
    "    \"multi_gpu\": multi_gpu,\n",
    "    \"number_of_gpus\": number_of_gpus,           \n",
    "    \"gpuid\": gpuid,\n",
    "    \"gpu_limit\": gpu_limit,\n",
    "    \"use_multiprocessing\": use_multiprocessing\n",
    "    }\n",
    "                       \n",
    "    def train(args):\n",
    "        \"\"\" \n",
    "        \n",
    "        Performs the training.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        args : dic\n",
    "            A dictionary object containing all of the input parameters. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        history: dic\n",
    "            Training history.  \n",
    "            \n",
    "        model: \n",
    "            Trained model.\n",
    "            \n",
    "        start_training: datetime\n",
    "            Training start time. \n",
    "            \n",
    "        end_training: datetime\n",
    "            Training end time. \n",
    "            \n",
    "        save_dir: str\n",
    "            Path to the output directory. \n",
    "            \n",
    "        save_models: str\n",
    "            Path to the folder for saveing the models.  \n",
    "            \n",
    "        training size: int\n",
    "            Number of training samples.\n",
    "            \n",
    "        validation size: int\n",
    "            Number of validation samples.  \n",
    "            \n",
    "        \"\"\"    \n",
    "\n",
    "        \n",
    "        save_dir, save_models=_make_dir(args['output_name'])\n",
    "        training, validation=_split(args, save_dir)\n",
    "        callbacks=_make_callback(args, save_models)\n",
    "        #model=_build_model(args)\n",
    "        #model.summary()  \n",
    "    \n",
    "        D1 = 5\n",
    "        D2 = int(D1*2)\n",
    "        D3 = int(D2*2)\n",
    "        D4 = int(D3*2)\n",
    "        D5 = int(D4*2)\n",
    "\n",
    "        inp = Input(shape=input_shape,name=\"input\")\n",
    "        conv1 = UNET(inp,D1)\n",
    "        out = Conv1D(D1,  3, strides =(1), padding='same',kernel_initializer='he_normal')(conv1)\n",
    "        out = Conv1D(3,  3, strides =(1), padding='same',kernel_initializer='he_normal',name='picker_PP')(out)\n",
    "        modeloriginal = Model(inp, out)\n",
    "\n",
    "        modeloriginal.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc',f1,precision, recall])     \n",
    "        modeloriginal.load_weights('../../../weights/UTrans_Foundation.h5')\n",
    "\n",
    "        # Model CCT\n",
    "        inputs = modeloriginal.layers[63].output  # layer that you want to connect your new FC layer to \n",
    "\n",
    "        features = create_vit_classifier(inputs,inp)\n",
    "        #features = Reshape((6000,1))(features)\n",
    "\n",
    "        e = Dense(1)(features)\n",
    "        o = Activation('linear', name='output_layer')(e)\n",
    "        model = Model(inputs=modeloriginal.input, outputs=o)\n",
    "        \n",
    "        Adm = tensorflow.optimizers.Adam(lr=1e-4)\n",
    "        model.compile(optimizer=Adm,\n",
    "                  loss='mse',\n",
    "                  metrics=['mse'])     \n",
    "\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if args['gpuid']:           \n",
    "            os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(gpuid)\n",
    "            tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            config.gpu_options.per_process_gpu_memory_fraction = float(args['gpu_limit']) \n",
    "            K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "            \n",
    "        start_training = time.time()                  \n",
    "            \n",
    "        if args['mode'] == 'generator': \n",
    "            \n",
    "            params_training = {'file_name': str(args['input_hdf5']), \n",
    "                              'dim': args['input_dimention'][0],\n",
    "                              'batch_size': args['batch_size'],\n",
    "                              'n_channels': args['input_dimention'][-1],\n",
    "                              'shuffle': args['shuffle'],  \n",
    "                              'norm_mode': args['normalization_mode'],\n",
    "                              'label_type': args['label_type'],                          \n",
    "                              'augmentation': args['augmentation'],\n",
    "                              'add_event_r': args['add_event_r'], \n",
    "                              'add_gap_r': args['add_gap_r'],  \n",
    "                              'shift_event_r': args['shift_event_r'],                            \n",
    "                              'add_noise_r': args['add_noise_r'], \n",
    "                              'drop_channe_r': args['drop_channel_r'],\n",
    "                              'scale_amplitude_r': args['scale_amplitude_r'],\n",
    "                              'pre_emphasis': args['pre_emphasis']}    \n",
    "                        \n",
    "            params_validation = {'file_name': str(args['input_hdf5']),  \n",
    "                                 'dim': args['input_dimention'][0],\n",
    "                                 'batch_size': args['batch_size'],\n",
    "                                 'n_channels': args['input_dimention'][-1],\n",
    "                                 'shuffle': False,  \n",
    "                                 'norm_mode': args['normalization_mode'],\n",
    "                                 'augmentation': False}         \n",
    "\n",
    "            training_generator = DataGenerator(training, **params_training)\n",
    "            validation_generator = DataGenerator(validation, **params_validation) \n",
    "\n",
    "            print('Started training in generator mode ...') \n",
    "            print(training_generator)\n",
    "            history = model.fit_generator(generator=training_generator,\n",
    "                                          validation_data=validation_generator,\n",
    "                                          use_multiprocessing=args['use_multiprocessing'],\n",
    "                                          workers=multiprocessing.cpu_count(),    \n",
    "                                          callbacks=callbacks, \n",
    "                                          epochs=args['epochs'],verbose=1)\n",
    "        else:\n",
    "            print('Please specify training_mode !', flush=True)\n",
    "        end_training = time.time()  \n",
    "        \n",
    "        return history, model, start_training, end_training, save_dir, save_models, len(training), len(validation)\n",
    "                  \n",
    "    history, model, start_training, end_training, save_dir, save_models, training_size, validation_size=train(args)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _make_dir(output_name):\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Make the output directories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output_name: str\n",
    "        Name of the output directory.\n",
    "                   \n",
    "    Returns\n",
    "    -------   \n",
    "    save_dir: str\n",
    "        Full path to the output directory.\n",
    "        \n",
    "    save_models: str\n",
    "        Full path to the model directory. \n",
    "        \n",
    "    \"\"\"   \n",
    "    \n",
    "    if output_name == None:\n",
    "        print('Please specify output_name!') \n",
    "        return\n",
    "    else:\n",
    "        save_dir = os.path.join(os.getcwd(), str(output_name)+'_outputs')\n",
    "        save_models = os.path.join(save_dir, 'models')      \n",
    "        if os.path.isdir(save_dir):\n",
    "            shutil.rmtree(save_dir)  \n",
    "        os.makedirs(save_models)\n",
    "    return save_dir, save_models\n",
    "\n",
    "\n",
    "\n",
    "def _build_model(args): \n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Build and compile the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args: dic\n",
    "        A dictionary containing all of the input parameters. \n",
    "               \n",
    "    Returns\n",
    "    -------   \n",
    "    model: \n",
    "        Compiled model.\n",
    "        \n",
    "    \"\"\"       \n",
    "    \n",
    "\n",
    "\n",
    "    # Model EQCCT\n",
    "    inputs = layers.Input(shape=input_shape,name='input')\n",
    "    \n",
    "    featuresS = create_cct_modelS(inputs)\n",
    "    featuresS = Reshape((6000,1))(featuresS)\n",
    "\n",
    "    logits  = Conv1D(1,  15, strides =(1), padding='same',activation='sigmoid', kernel_initializer='he_normal',name='picker_S')(featuresS)\n",
    "    model = Model(inputs=[inputs], outputs=[logits])    \n",
    "    \n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc',f1,precision, recall])    \n",
    "    \n",
    "  \n",
    "    return model  \n",
    "    \n",
    "\n",
    "def _split(args, save_dir):\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Split the list of input data into training, validation, and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args: dic\n",
    "        A dictionary containing all of the input parameters. \n",
    "        \n",
    "    save_dir: str\n",
    "       Path to the output directory. \n",
    "              \n",
    "    Returns\n",
    "    -------   \n",
    "    training: str\n",
    "        List of trace names for the training set. \n",
    "    validation : str\n",
    "        List of trace names for the validation set. \n",
    "                \n",
    "    \"\"\"       \n",
    "    \n",
    "    # Loading the IDs.\n",
    "    training = np.load('train_Events.npy')\n",
    "    validation = np.load('valid_Events.npy')\n",
    "    test = np.load('test_Events.npy')\n",
    "\n",
    "    return training, validation \n",
    "\n",
    "\n",
    "\n",
    "def _make_callback(args, save_models):\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Generate the callback.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args: dic\n",
    "        A dictionary containing all of the input parameters. \n",
    "        \n",
    "    save_models: str\n",
    "       Path to the output directory for the models. \n",
    "              \n",
    "    Returns\n",
    "    -------   \n",
    "    callbacks: obj\n",
    "        List of callback objects. \n",
    "        \n",
    "        \n",
    "    \"\"\"    \n",
    "    \n",
    "    m_name=str(args['output_name'])+'_{epoch:03d}.h5'   \n",
    "    filepath=os.path.join(save_models, m_name)  \n",
    "    early_stopping_monitor=EarlyStopping(monitor=args['monitor'], \n",
    "                                           patience=args['patience']) \n",
    "    checkpoint=ModelCheckpoint(filepath=filepath,\n",
    "                                 monitor=args['monitor'], \n",
    "                                 mode='auto',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                  save_weights_only=True)  \n",
    "    lr_scheduler=LearningRateScheduler(_lr_schedule)\n",
    "\n",
    "    lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                                   cooldown=0,\n",
    "                                   patience=args['patience']-2,\n",
    "                                   min_lr=0.5e-6)\n",
    "\n",
    "    callbacks = [checkpoint, lr_reducer, lr_scheduler, early_stopping_monitor]\n",
    "    return callbacks\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "def _pre_loading(args, training, validation):\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Load data into memory.\n",
    "create_cct_modelS\n",
    "    Parameters\n",
    "    ----------\n",
    "    args: dic\n",
    "        A dictionary containing all of the input parameters. \n",
    "        \n",
    "    training: str\n",
    "        List of trace names for the training set. \n",
    "        \n",
    "    validation: str\n",
    "        List of trace names for the validation set. \n",
    "              \n",
    "    Returns\n",
    "    -------   \n",
    "    training_generator: obj\n",
    "        Keras generator for the training set. \n",
    "        \n",
    "    validation_generator: obj\n",
    "        Keras generator for the validation set. \n",
    "        \n",
    "        \n",
    "    \"\"\"   \n",
    "    \n",
    "    training_set={}\n",
    "    fl = h5py.File(args['input_hdf5'], 'r')   \n",
    "    \n",
    "    print('Loading the training data into the memory ...')\n",
    "    pbar = tqdm(total=len(training)) \n",
    "    for ID in training:\n",
    "        pbar.update()\n",
    "        if ID.split('_')[-1] == 'EV':\n",
    "            dataset = fl.get(str(ID))\n",
    "        elif ID.split('_')[-1] == 'NO':\n",
    "            dataset = fl.get(str(ID))\n",
    "        training_set.update( {str(ID) : dataset})  \n",
    "\n",
    "    print('Loading the validation data into the memory ...', flush=True)            \n",
    "    validation_set={}\n",
    "    pbar = tqdm(total=len(validation)) \n",
    "    for ID in validation:\n",
    "        pbar.update()\n",
    "        if ID.split('_')[-1] == 'EV':\n",
    "            dataset = fl.get(str(ID))\n",
    "        elif ID.split('_')[-1] == 'NO':\n",
    "            dataset = fl.get(str(ID))\n",
    "        validation_set.update( {str(ID) : dataset})  \n",
    "   \n",
    "    params_training = {'dim':args['input_dimention'][0],\n",
    "                       'batch_size': args['batch_size'],\n",
    "                       'n_channels': args['input_dimention'][-1],\n",
    "                       'shuffle': args['shuffle'],  \n",
    "                       'norm_mode': args['normalization_mode'],\n",
    "                       'label_type': args['label_type'],\n",
    "                       'augmentation': args['augmentation'],\n",
    "                       'add_event_r': args['add_event_r'], \n",
    "                       'add_gap_r': args['add_gap_r'],                         \n",
    "                       'shift_event_r': args['shift_event_r'],  \n",
    "                       'add_noise_r': args['add_noise_r'], \n",
    "                       'drop_channe_r': args['drop_channel_r'],\n",
    "                       'scale_amplitude_r': args['scale_amplitude_r'],\n",
    "                       'pre_emphasis': args['pre_emphasis']}  \n",
    "\n",
    "    params_validation = {'dim': args['input_dimention'][0],\n",
    "                         'batch_size': args['batch_size'],\n",
    "                         'n_channels': args['input_dimention'][-1],\n",
    "                         'shuffle': False,  \n",
    "                         'norm_mode': args['normalization_mode'],\n",
    "                         'augmentation': False}  \n",
    "    \n",
    "    training_generator = PreLoadGenerator(training, training_set, **params_training)  \n",
    "    validation_generator = PreLoadGenerator(validation, validation_set, **params_validation) \n",
    "    \n",
    "    return training_generator, validation_generator  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbaaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer1(input_hdf5= '/scratch/sadalyom/DataCollected',\n",
    "        output_name='test_trainer_FoundationVit_Mag',                 \n",
    "        shuffle=True, \n",
    "        label_type='triangle',\n",
    "        normalization_mode='std',\n",
    "        augmentation=True,\n",
    "        add_event_r=None,\n",
    "        shift_event_r=0.99,\n",
    "        add_noise_r=0.5, \n",
    "        drop_channel_r=0.1,\n",
    "        add_gap_r=None,\n",
    "        scale_amplitude_r=None,\n",
    "        pre_emphasis=False,               \n",
    "        mode='generator',\n",
    "        batch_size=40,\n",
    "        epochs=50, \n",
    "        patience=10,\n",
    "        gpuid=None,\n",
    "        gpu_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3810924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
