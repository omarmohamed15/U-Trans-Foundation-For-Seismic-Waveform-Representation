{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e88a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf1\n",
    "tf1.disable_v2_behavior()\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "tf.config.experimental.set_visible_devices(physical_devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import shutil\n",
    "import logging\n",
    "import warnings\n",
    "import platform\n",
    "import contextlib\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "import faulthandler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy import signal\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import callbacks, constraints, initializers, layers, models, optimizers, regularizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing import sequence, text\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    Callback,\n",
    "    EarlyStopping,\n",
    "    LearningRateScheduler,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Add,\n",
    "    Average,\n",
    "    AveragePooling2D,\n",
    "    BatchNormalization,\n",
    "    Bidirectional,\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling1D,\n",
    "    GlobalAveragePooling2D,\n",
    "    GlobalMaxPooling1D,\n",
    "    GRU,\n",
    "    Input,\n",
    "    Lambda,\n",
    "    LSTM,\n",
    "    MaxPooling1D,\n",
    "    MaxPooling2D,\n",
    "    Permute,\n",
    "    Reshape,\n",
    "    SeparableConv1D,\n",
    "    SpatialDropout1D,\n",
    "    UpSampling1D,\n",
    "    UpSampling2D,\n",
    "    concatenate,\n",
    "    multiply,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from numpy.random import seed\n",
    "\n",
    "# Environment / runtime settings\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "matplotlib.use(\"agg\")\n",
    "faulthandler.enable()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Silence TF deprecation warnings (internal API; keep only if you really need it)\n",
    "from tensorflow.python.util import deprecation  # noqa: E402\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Compute recall metric.\"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Compute precision metric.\"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Compute F1 score metric.\"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d79f7",
   "metadata": {},
   "source": [
    "## Foundation Model (U-Trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb2b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, UpSampling1D, concatenate\n",
    "\n",
    "# -----------------------------\n",
    "# U-Trans (Foundation) settings\n",
    "# -----------------------------\n",
    "STOCHASTIC_DEPTH_RATE = 0.1\n",
    "POSITIONAL_EMB = False\n",
    "CONV_LAYERS = 1\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "INPUT_SHAPE = (375, 256)\n",
    "\n",
    "PROJECTION_DIM = 80\n",
    "NUM_HEADS = 4\n",
    "TRANSFORMER_UNITS = [PROJECTION_DIM, PROJECTION_DIM]\n",
    "TRANSFORMER_LAYERS = 4\n",
    "\n",
    "\n",
    "def mlp(x, hidden_units, dropout_rate: float):\n",
    "    \"\"\"Feed-forward MLP block used inside the transformer.\"\"\"\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Referred from: github.com:rwightman/pytorch-image-models\n",
    "class StochasticDepth(layers.Layer):\n",
    "    \"\"\"Stochastic depth (a.k.a. DropPath) layer.\"\"\"\n",
    "\n",
    "    def __init__(self, drop_prob: float, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_prob = float(drop_prob)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            keep_prob = 1.0 - self.drop_prob\n",
    "            shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n",
    "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
    "            binary_tensor = tf.floor(random_tensor)\n",
    "            return (x / keep_prob) * binary_tensor\n",
    "        return x\n",
    "\n",
    "\n",
    "class CCTTokenizer1(layers.Layer):\n",
    "    \"\"\"Compact Convolutional Transformer (CCT) tokenizer for 1D signals.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        num_conv_layers: int = CONV_LAYERS,\n",
    "        num_output_channels=None,\n",
    "        positional_emb: bool = POSITIONAL_EMB,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if num_output_channels is None:\n",
    "            # Provide enough channels for any reasonable num_conv_layers\n",
    "            num_output_channels = [int(PROJECTION_DIM)] * 8\n",
    "\n",
    "        self.positional_emb = positional_emb\n",
    "\n",
    "        conv_stack = []\n",
    "        for i in range(num_conv_layers):\n",
    "            conv_stack.append(\n",
    "                layers.Conv1D(\n",
    "                    filters=num_output_channels[i],\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=stride,\n",
    "                    padding=\"same\",\n",
    "                    use_bias=False,\n",
    "                    activation=\"relu\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                )\n",
    "            )\n",
    "        self.conv_model = tf.keras.Sequential(conv_stack)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Output shape: (batch, length, channels) -> already token-like for transformer\n",
    "        return self.conv_model(inputs)\n",
    "\n",
    "    def positional_embedding(self, image_size: int):\n",
    "        \"\"\"Optional positional embeddings (kept for parity with original code).\"\"\"\n",
    "        if not self.positional_emb:\n",
    "            return None\n",
    "\n",
    "        dummy_inputs = tf.ones((1, image_size, 1))\n",
    "        dummy_outputs = self.call(dummy_inputs)\n",
    "        seq_length = int(dummy_outputs.shape[1])\n",
    "        proj_dim = int(dummy_outputs.shape[-1])\n",
    "\n",
    "        embed_layer = layers.Embedding(input_dim=seq_length, output_dim=proj_dim)\n",
    "        return embed_layer, seq_length\n",
    "\n",
    "\n",
    "def create_cct_model1(inputs):\n",
    "    \"\"\"Transformer encoder over 1D tokens produced by CCTTokenizer1.\"\"\"\n",
    "    cct_tokenizer = CCTTokenizer1()\n",
    "    encoded_patches = cct_tokenizer(inputs)\n",
    "\n",
    "    if POSITIONAL_EMB:\n",
    "        # NOTE: image_size must be defined by the caller if enabling positional embeddings.\n",
    "        # pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n",
    "        # positions = tf.range(start=0, limit=seq_length, delta=1)\n",
    "        # encoded_patches += pos_embed(positions)\n",
    "        raise ValueError(\"POSITIONAL_EMB=True requires defining image_size and enabling the code block.\")\n",
    "\n",
    "    dpr = np.linspace(0, STOCHASTIC_DEPTH_RATE, TRANSFORMER_LAYERS).tolist()\n",
    "\n",
    "    for i in range(TRANSFORMER_LAYERS):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=NUM_HEADS,\n",
    "            key_dim=PROJECTION_DIM,\n",
    "            dropout=0.1,\n",
    "        )(x1, x1)\n",
    "\n",
    "        attention_output = StochasticDepth(dpr[i])(attention_output)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-5)(x2)\n",
    "        x3 = mlp(x3, hidden_units=TRANSFORMER_UNITS, dropout_rate=0.1)\n",
    "\n",
    "        x3 = StochasticDepth(dpr[i])(x3)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    return layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "\n",
    "\n",
    "def UNET(inputs, d1: int):\n",
    "    \"\"\"1D U-Net with a CCT transformer bottleneck (U-Trans).\"\"\"\n",
    "    d2, d3, d4, d5 = d1 * 2, d1 * 4, d1 * 8, d1 * 16\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv1D(d1, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(inputs)\n",
    "    conv1 = Conv1D(d1, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "\n",
    "    conv2 = Conv1D(d2, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(pool1)\n",
    "    conv2 = Conv1D(d2, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "\n",
    "    conv3 = Conv1D(d3, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(pool2)\n",
    "    conv3 = Conv1D(d3, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(conv3)\n",
    "\n",
    "    conv4 = Conv1D(d4, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(pool3)\n",
    "    conv4 = Conv1D(d4, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv4)\n",
    "    pool4 = MaxPooling1D(pool_size=2)(conv4)\n",
    "\n",
    "    conv44 = Conv1D(d5, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(pool4)\n",
    "    conv44 = Conv1D(d5, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv44)\n",
    "    pool44 = MaxPooling1D(pool_size=5)(conv44)\n",
    "\n",
    "    # Bottleneck + Transformer\n",
    "    conv5 = Conv1D(d5, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(pool44)\n",
    "    conv5 = Conv1D(d5, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv5)\n",
    "    drop5 = create_cct_model1(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up66 = Conv1D(d5, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(\n",
    "        UpSampling1D(size=5)(drop5)\n",
    "    )\n",
    "    merge66 = concatenate([pool4, up66], axis=-1)\n",
    "    conv66 = Conv1D(d5, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(merge66)\n",
    "    conv66 = Conv1D(d5, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv66)\n",
    "\n",
    "    up6 = Conv1D(d4, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(\n",
    "        UpSampling1D(size=2)(conv66)\n",
    "    )\n",
    "    merge6 = concatenate([conv4, up6], axis=-1)\n",
    "    conv6 = Conv1D(d4, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(merge6)\n",
    "    conv6 = Conv1D(d4, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv6)\n",
    "\n",
    "    up7 = Conv1D(d3, 2, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(\n",
    "        UpSampling1D(size=2)(conv6)\n",
    "    )\n",
    "    merge7 = concatenate([conv3, up7], axis=-1)\n",
    "    conv7 = Conv1D(d3, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(merge7)\n",
    "    conv7 = Conv1D(d3, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv7)\n",
    "\n",
    "    up8 = Conv1D(d2, 2, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(\n",
    "        UpSampling1D(size=2)(conv7)\n",
    "    )\n",
    "    merge8 = concatenate([conv2, up8], axis=-1)\n",
    "    conv8 = Conv1D(d2, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(merge8)\n",
    "    conv8 = Conv1D(d2, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv8)\n",
    "\n",
    "    up9 = Conv1D(d1, 2, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(\n",
    "        UpSampling1D(size=2)(conv8)\n",
    "    )\n",
    "    merge9 = concatenate([conv1, up9], axis=-1)\n",
    "    conv9 = Conv1D(d1, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(merge9)\n",
    "    conv9 = Conv1D(d1, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(conv9)\n",
    "\n",
    "    return conv9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c121f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114136d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import datetime\n",
    "import multiprocessing\n",
    "import warnings\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv1D\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ReduceLROnPlateau,\n",
    "    LearningRateScheduler,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "\n",
    "from EqT_utils_Recon import DataGenerator, _lr_schedule\n",
    "input_shape=(6000, 3)\n",
    "matplotlib.use(\"agg\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.python.util import deprecation  # noqa: E402\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "\n",
    "def trainer1(\n",
    "    input_hdf5=None,\n",
    "    input_csv=None,\n",
    "    output_name=None,\n",
    "    input_dimention=(6000, 3),\n",
    "    cnn_blocks=5,\n",
    "    lstm_blocks=2,\n",
    "    padding=\"same\",\n",
    "    activation=\"relu\",\n",
    "    drop_rate=0.1,\n",
    "    shuffle=True,\n",
    "    loss_types = 'mse',\n",
    "    normalization_mode=\"std\",\n",
    "    augmentation=True,\n",
    "    add_event_r=0.6,\n",
    "    shift_event_r=0.99,\n",
    "    add_noise_r=0.3,\n",
    "    drop_channel_r=0.5,\n",
    "    add_gap_r=0.2,\n",
    "    scale_amplitude_r=None,\n",
    "    pre_emphasis=False,\n",
    "    train_valid_test_split=(0.85, 0.05, 0.10),\n",
    "    mode=\"generator\",\n",
    "    batch_size=200,\n",
    "    epochs=200,\n",
    "    monitor=\"val_loss\",\n",
    "    patience=12,\n",
    "    multi_gpu=False,\n",
    "    number_of_gpus=4,\n",
    "    gpuid=None,\n",
    "    gpu_limit=None,\n",
    "    use_multiprocessing=True,\n",
    "):\n",
    "    \"\"\"Train the reconstruction model to recover clean signals from corrupted time/frequency data.\"\"\"\n",
    "\n",
    "    args = {\n",
    "        \"input_hdf5\": input_hdf5,\n",
    "        \"input_csv\": input_csv,\n",
    "        \"output_name\": output_name,\n",
    "        \"input_dimention\": input_dimention,\n",
    "        \"cnn_blocks\": cnn_blocks,\n",
    "        \"lstm_blocks\": lstm_blocks,\n",
    "        \"padding\": padding,\n",
    "        \"loss_types\":loss_types,\n",
    "        \"activation\": activation,\n",
    "        \"drop_rate\": drop_rate,\n",
    "        \"shuffle\": shuffle,\n",
    "        \"normalization_mode\": normalization_mode,\n",
    "        \"augmentation\": augmentation,\n",
    "        \"add_event_r\": add_event_r,\n",
    "        \"shift_event_r\": shift_event_r,\n",
    "        \"add_noise_r\": add_noise_r,\n",
    "        \"add_gap_r\": add_gap_r,\n",
    "        \"drop_channel_r\": drop_channel_r,\n",
    "        \"scale_amplitude_r\": scale_amplitude_r,\n",
    "        \"pre_emphasis\": pre_emphasis,\n",
    "        \"train_valid_test_split\": train_valid_test_split,\n",
    "        \"mode\": mode,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"monitor\": monitor,\n",
    "        \"patience\": patience,\n",
    "        \"multi_gpu\": multi_gpu,\n",
    "        \"number_of_gpus\": number_of_gpus,\n",
    "        \"gpuid\": gpuid,\n",
    "        \"gpu_limit\": gpu_limit,\n",
    "        \"use_multiprocessing\": use_multiprocessing,\n",
    "    }\n",
    "\n",
    "    def train(cfg):\n",
    "        save_dir, save_models = _make_dir(cfg[\"output_name\"])\n",
    "        training, validation = _split(cfg, save_dir)\n",
    "        cb = _make_callback(cfg, save_models)\n",
    "        model = _build_model(cfg)\n",
    "        model.summary()\n",
    "\n",
    "        if cfg[\"gpuid\"] is not None:\n",
    "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(cfg[\"gpuid\"])\n",
    "            config = tf.compat.v1.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            if cfg[\"gpu_limit\"] is not None:\n",
    "                config.gpu_options.per_process_gpu_memory_fraction = float(cfg[\"gpu_limit\"])\n",
    "            sess = tf.compat.v1.Session(config=config)\n",
    "            tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "        start_training = time.time()\n",
    "\n",
    "        if cfg[\"mode\"] != \"generator\":\n",
    "            raise ValueError(\"Only mode='generator' is supported in this cell.\")\n",
    "\n",
    "        params_training = {\n",
    "            \"file_name\": str(cfg[\"input_hdf5\"]),\n",
    "            \"dim\": cfg[\"input_dimention\"][0],\n",
    "            \"batch_size\": cfg[\"batch_size\"],\n",
    "            \"n_channels\": cfg[\"input_dimention\"][-1],\n",
    "            \"shuffle\": cfg[\"shuffle\"],\n",
    "            \"norm_mode\": cfg[\"normalization_mode\"],\n",
    "            \"augmentation\": cfg[\"augmentation\"],\n",
    "            \"add_event_r\": cfg[\"add_event_r\"],\n",
    "            \"add_gap_r\": cfg[\"add_gap_r\"],\n",
    "            \"shift_event_r\": cfg[\"shift_event_r\"],\n",
    "            \"add_noise_r\": cfg[\"add_noise_r\"],\n",
    "            \"drop_channe_r\": cfg[\"drop_channel_r\"],\n",
    "            \"scale_amplitude_r\": cfg[\"scale_amplitude_r\"],\n",
    "            \"pre_emphasis\": cfg[\"pre_emphasis\"],\n",
    "        }\n",
    "\n",
    "        params_validation = {\n",
    "            \"file_name\": str(cfg[\"input_hdf5\"]),\n",
    "            \"dim\": cfg[\"input_dimention\"][0],\n",
    "            \"batch_size\": cfg[\"batch_size\"],\n",
    "            \"n_channels\": cfg[\"input_dimention\"][-1],\n",
    "            \"shuffle\": False,\n",
    "            \"norm_mode\": cfg[\"normalization_mode\"],\n",
    "            \"augmentation\": False,\n",
    "        }\n",
    "\n",
    "        training_generator = DataGenerator(training, **params_training)\n",
    "        validation_generator = DataGenerator(validation, **params_validation)\n",
    "\n",
    "        history = model.fit(\n",
    "            training_generator,\n",
    "            validation_data=validation_generator,\n",
    "            use_multiprocessing=cfg[\"use_multiprocessing\"],\n",
    "            workers=multiprocessing.cpu_count(),\n",
    "            callbacks=cb,\n",
    "            epochs=cfg[\"epochs\"],\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        end_training = time.time()\n",
    "        return history, model, start_training, end_training, save_dir, save_models, len(training), len(validation)\n",
    "\n",
    "    history, model, start_training, end_training, save_dir, save_models, training_size, validation_size = train(args)\n",
    "\n",
    "\n",
    "\n",
    "def _make_dir(output_name):\n",
    "    \"\"\"Create output directories (overwrite if exists).\"\"\"\n",
    "    if output_name is None:\n",
    "        raise ValueError(\"Please specify output_name.\")\n",
    "\n",
    "    save_dir = os.path.join(os.getcwd(), f\"{output_name}_outputs\")\n",
    "    save_models = os.path.join(save_dir, \"models\")\n",
    "\n",
    "    if os.path.isdir(save_dir):\n",
    "        shutil.rmtree(save_dir)\n",
    "    os.makedirs(save_models, exist_ok=True)\n",
    "\n",
    "    return save_dir, save_models\n",
    "\n",
    "\n",
    "def _build_model(args):\n",
    "    \"\"\"Build and compile the reconstruction model.\"\"\"\n",
    "    d1 = 5\n",
    "    inp = Input(shape=input_shape, name=\"input\")  # expects `input_shape` and `UNET` to be defined\n",
    "    x = UNET(inp, d1)\n",
    "\n",
    "    x = Conv1D(d1, 3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    out = Conv1D(3, 3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\", name=\"reconstruction\")(x)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def _split(args, save_dir):\n",
    "    \"\"\"Load pre-defined train/valid/test IDs and return train/valid splits.\"\"\"\n",
    "    training = np.load(\"IDS_Collected_Data_train.npy\")    \n",
    "    validation = np.load(\"IDS_Collected_Data_valid.npy\")\n",
    "    _ = np.load(\"IDS_Collected_Data_test.npy\")  # loaded to keep parity; not used here\n",
    "    return training, validation\n",
    "\n",
    "\n",
    "def _make_callback(args, save_models):\n",
    "    \"\"\"Callbacks: checkpoint, LR reducer, scheduler, and early stopping.\"\"\"\n",
    "    model_name = f\"{args['output_name']}\" + \"_{epoch:03d}.h5\"\n",
    "    filepath = os.path.join(save_models, model_name)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=filepath,\n",
    "        monitor=args[\"monitor\"],\n",
    "        mode=\"auto\",\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    lr_reducer = ReduceLROnPlateau(\n",
    "        factor=np.sqrt(0.1),\n",
    "        cooldown=0,\n",
    "        patience=args[\"patience\"] - 2,\n",
    "        min_lr=0.5e-6,\n",
    "    )\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(_lr_schedule)\n",
    "    early_stop = EarlyStopping(monitor=args[\"monitor\"], patience=args[\"patience\"])\n",
    "\n",
    "    return [checkpoint, lr_reducer, lr_scheduler, early_stop]\n",
    "\n",
    "\n",
    "def _pre_loading(args, training, validation):\n",
    "    \"\"\"Optional: load HDF5 into memory (kept for compatibility).\"\"\"\n",
    "    training_set = {}\n",
    "    fl = h5py.File(args[\"input_hdf5\"], \"r\")\n",
    "\n",
    "    print(\"Loading the training data into memory ...\")\n",
    "    pbar = tqdm(total=len(training))\n",
    "    for trace_id in training:\n",
    "        pbar.update()\n",
    "        dataset = fl.get(str(trace_id))\n",
    "        training_set[str(trace_id)] = dataset\n",
    "\n",
    "    print(\"Loading the validation data into memory ...\", flush=True)\n",
    "    validation_set = {}\n",
    "    pbar = tqdm(total=len(validation))\n",
    "    for trace_id in validation:\n",
    "        pbar.update()\n",
    "        dataset = fl.get(str(trace_id))\n",
    "        validation_set[str(trace_id)] = dataset\n",
    "\n",
    "    params_training = {\n",
    "        \"dim\": args[\"input_dimention\"][0],\n",
    "        \"batch_size\": args[\"batch_size\"],\n",
    "        \"n_channels\": args[\"input_dimention\"][-1],\n",
    "        \"shuffle\": args[\"shuffle\"],\n",
    "        \"norm_mode\": args[\"normalization_mode\"],\n",
    "        \"augmentation\": args[\"augmentation\"],\n",
    "        \"add_event_r\": args[\"add_event_r\"],\n",
    "        \"add_gap_r\": args[\"add_gap_r\"],\n",
    "        \"shift_event_r\": args[\"shift_event_r\"],\n",
    "        \"add_noise_r\": args[\"add_noise_r\"],\n",
    "        \"drop_channe_r\": args[\"drop_channel_r\"],\n",
    "        \"scale_amplitude_r\": args[\"scale_amplitude_r\"],\n",
    "        \"pre_emphasis\": args[\"pre_emphasis\"],\n",
    "    }\n",
    "\n",
    "    params_validation = {\n",
    "        \"dim\": args[\"input_dimention\"][0],\n",
    "        \"batch_size\": args[\"batch_size\"],\n",
    "        \"n_channels\": args[\"input_dimention\"][-1],\n",
    "        \"shuffle\": False,\n",
    "        \"norm_mode\": args[\"normalization_mode\"],\n",
    "        \"augmentation\": False,\n",
    "    }\n",
    "\n",
    "    training_generator = PreLoadGenerator(training, training_set, **params_training)  # expects PreLoadGenerator\n",
    "    validation_generator = PreLoadGenerator(validation, validation_set, **params_validation)\n",
    "    return training_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53771ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer1(input_hdf5= r'/scratch/sadalyom/DataCollected',\n",
    "        input_csv  = '',\n",
    "        output_name='test_trainer_2',                \n",
    "        shuffle=True, \n",
    "        normalization_mode='std',\n",
    "        augmentation=True,\n",
    "        add_event_r=0.5,\n",
    "        shift_event_r=0.99,\n",
    "        add_noise_r=0.5, \n",
    "        drop_channel_r=False,\n",
    "        add_gap_r=None,\n",
    "        scale_amplitude_r=None,\n",
    "        pre_emphasis=False,               \n",
    "        loss_types='mae',\n",
    "        mode='generator',\n",
    "        batch_size=40,\n",
    "        epochs=50, \n",
    "        patience=10,\n",
    "        gpuid=None,\n",
    "        gpu_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b9cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84986cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Foundation",
   "language": "python",
   "name": "foundation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
